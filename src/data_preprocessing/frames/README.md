# ğŸ“Œ Video Frame Extraction

## ğŸ“‚ Overview
This project extracts frames from a **video dataset**, specifically from **Training Data 1/6**, as a sample.

The purpose of this extraction is to demonstrate the process of converting video files into individual frames.

---

## ğŸ“¥ Download the Dataset
You can download the video dataset from the official **ChaLearn LAP** page:  
ğŸ‘‰ [ChaLearn LAP Dataset - Video Files](https://chalearnlap.cvc.uab.cat/dataset/24/data/41/files/)

Ensure that you have the correct dataset files before proceeding with the extraction.

---
## ğŸ“¥ Extracted Data
âœ… **Dataset:** Training Data **1/6** (Sample)  
âœ… **Output Format:** `.jpg.npy` images  
âœ… **Frame Extraction Method:** `torchvision.io.read_video()`  

---

# ğŸ“Œ Execution files

### **1ï¸âƒ£ Single-Processing Method** (`make_video_frames_single_processing.ipynb`)
âœ… **Description**:  
- Uses a **single CPU core** to process video frames sequentially.  
- Suitable for small datasets but **slower for large-scale video processing**.  
- Implemented in a **Jupyter Notebook** for easy demonstration and experimentation.

### **2ï¸âƒ£ Multi-Processing Method (Python Script)** (`make_video_frames_multi_processing.py`)
âœ… **Description**:

- Uses **multiple CPU cores** to process multiple videos in parallel.
- Significantly faster than the single-processing approach, especially for large datasets.
- Recommended for real-world applications where speed is critical.